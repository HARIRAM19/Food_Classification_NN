# -*- coding: utf-8 -*-
"""Deep Learning - IBM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18so5YqaLS3FW9zeg7STKBv89YykxGGCx
"""

import seaborn as sns
import cv2
import keras
import os
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow import keras
from keras.optimizers import Adam
from keras.models import Sequential
from sklearn.metrics import classification_report,confusion_matrix
from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout

from google.colab import drive
drive.mount('/content/drive')

categories = os.listdir('/content/drive/MyDrive/food20dataset/train_set')
img_size= 224
def get_data(data_dir):
    data=[]
    for category in categories:
        path= os.path.join(data_dir,category)
        class_num= categories.index(category)
        print(path)
        for img in os.listdir(path):
            try:
                img_arr= cv2.imread(os.path.join(path,img))
                resized_arr= cv2.resize(img_arr,(img_size,img_size))
                data.append([resized_arr, class_num])
            except Exception as e:
                print(e)
    return np.array(data)

train = get_data('/content/drive/MyDrive/food20dataset/train_set')  
val = get_data('/content/drive/MyDrive/food20dataset/test_set')

x_train = []
y_train = []
x_val = []
y_val = []

for feature, label in train:
    x_train.append(feature)
    y_train.append(label)
    
for feature, label in val:
    x_val.append(feature)
    y_val.append(label)
    
x_train = np.array(x_train) / 255
x_val = np.array(x_val) / 255

x_train.reshape(-1, img_size,img_size,1)
y_train = np.array(y_train)

x_val.reshape(-1,img_size,img_size,1)
y_val = np.array(y_val)

!pip install visualkeras
import visualkeras

base_model = tf.keras.applications.MobileNetV2(input_shape = (224,224,3), include_top=False, weights='imagenet')
base_model.trainable=False
model = tf.keras.Sequential([base_model, tf.keras.layers.GlobalAveragePooling2D(), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(512,activation='relu'),tf.keras.layers.Dense(20,activation='softmax')])
model.summary()

base_learning_rate = 0.1
model.compile(optimizer = tf.keras.optimizers.Adam(lr=base_learning_rate), loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
history1 = model.fit(x_train,y_train,epochs = 15, validation_data=(x_val,y_val))

epochs_range = range(15)
acc = history1.history['accuracy']
val_acc = history1.history['val_accuracy']
loss = history1.history['loss']
val_loss = history1.history['val_loss']
fig,(ax1,ax2) = plt.subplots(1,2,figsize=(15,6))
plt.rc('xtick',labelsize=10)
plt.rc('ytick',labelsize=10)
ax1.plot(epochs_range,acc,label='Training Accuracy',c='blue',linewidth = 4)
ax1.plot(epochs_range,val_acc, label='validation_accuracy',c='red',linewidth=4)
ax1.legend()
ax1.set_title('Training and Accuracy')
ax1.set_xlabel('Accuracy', fontsize=10)
ax1.set_ylabel('Val_accuracy', fontsize=10)
ax2.plot(epochs_range,loss,label='Training Loss',c='green',linewidth = 4)
ax2.plot(epochs_range,val_loss, label='vaalidation_loss',c='orange',linewidth=4)
ax2.legend()
ax2.set_title('Training and Validation')
ax2.set_xlabel('Loss', fontsize=10)
ax2.set_ylabel('Val_loss', fontsize=10)
fig.tight_layout(pad=3.0)
plt.show()

visualkeras.layered_view(model)

from keras.applications import VGG19

base_model= VGG19(include_top=False,
    weights="imagenet",
    input_tensor=None,
    input_shape=(224,224,3),
    pooling=None)
base_model.trainable= False

model= Sequential()
model.add(base_model)
model.add(tf.keras.layers.GlobalAveragePooling2D())
model.add(Dropout(0.2))
model.add(Dense(512,activation='relu'))
model.add(Dense(20,activation='softmax'))
model.summary()

model.compile(Adam(lr=0.001), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
history2 = model.fit(x_train,y_train,epochs = 15 , validation_data = (x_val, y_val))

epochs_range = range(15)
acc = history2.history['accuracy']
val_acc = history2.history['val_accuracy']
loss = history2.history['loss']
val_loss = history2.history['val_loss']
fig,(ax1,ax2) = plt.subplots(1,2,figsize=(15,6))
plt.rc('xtick',labelsize=10)
plt.rc('ytick',labelsize=10)
ax1.plot(epochs_range,acc,label='Training Accuracy',c='blue',linewidth = 4)
ax1.plot(epochs_range,val_acc, label='validation_accuracy',c='red',linewidth=4)
ax1.legend()
ax1.set_title('Training and Accuracy')
ax1.set_xlabel('Accuracy', fontsize=10)
ax1.set_ylabel('Val_accuracy', fontsize=10)
ax2.plot(epochs_range,loss,label='Training Loss',c='green',linewidth = 4)
ax2.plot(epochs_range,val_loss, label='vaalidation_loss',c='orange',linewidth=4)
ax2.legend()
ax2.set_title('Training and Validation')
ax2.set_xlabel('Loss', fontsize=10)
ax2.set_ylabel('Val_loss', fontsize=10)
fig.tight_layout(pad=3.0)
plt.show()

visualkeras.layered_view(model)

from keras.applications import InceptionResNetV2

base_model= InceptionResNetV2(include_top=False,
    weights="imagenet",
    input_tensor=None,
    input_shape=(224,224,3))
base_model.trainable= False

model= Sequential()
model.add(base_model)
model.add(tf.keras.layers.GlobalAveragePooling2D())
model.add(Dropout(0.2))
model.add(Dense(20,activation='softmax'))
model.summary()

model.compile(Adam(lr=0.001), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
history3 = model.fit(x_train,y_train,epochs = 15 , validation_data = (x_val, y_val))

epochs_range = range(15)
acc = history3.history['accuracy']
val_acc = history3.history['val_accuracy']
loss = history3.history['loss']
val_loss = history3.history['val_loss']
fig,(ax1,ax2) = plt.subplots(1,2,figsize=(15,6))
plt.rc('xtick',labelsize=10)
plt.rc('ytick',labelsize=10)
ax1.plot(epochs_range,acc,label='Training Accuracy',c='blue',linewidth = 4)
ax1.plot(epochs_range,val_acc, label='validation_accuracy',c='red',linewidth=4)
ax1.legend()
ax1.set_title('Training and Accuracy')
ax1.set_xlabel('Accuracy', fontsize=10)
ax1.set_ylabel('Val_accuracy', fontsize=10)
ax2.plot(epochs_range,loss,label='Training Loss',c='green',linewidth = 4)
ax2.plot(epochs_range,val_loss, label='vaalidation_loss',c='orange',linewidth=4)
ax2.legend()
ax2.set_title('Training and Validation')
ax2.set_xlabel('Loss', fontsize=10)
ax2.set_ylabel('Val_loss', fontsize=10)
fig.tight_layout(pad=3.0)
plt.show()

visualkeras.layered_view(model)

# Model Comparision
epochs_range = range(15)

val_acc1 = history1.history['val_accuracy']
val_acc2 = history2.history['val_accuracy']
val_acc3 = history3.history['val_accuracy']

val_loss1 = history1.history['val_loss']
val_loss2 = history2.history['val_loss']
val_loss3 = history3.history['val_loss']

fig,(ax1,ax2) = plt.subplots(1,2,figsize=(15,6))

plt.rc('xtick',labelsize=10)
plt.rc('ytick',labelsize=10)


ax1.plot(epochs_range,val_acc1, label='MobileNetV2',c='red',linewidth=2)
ax1.plot(epochs_range,val_acc2, label='VGG19',c='green',linewidth=2)
ax1.plot(epochs_range,val_acc3, label='InceptionResNetV2',c='blue',linewidth=2)
ax1.legend()

ax1.set_title('Training and Accuracy')

ax2.plot(epochs_range,val_loss1, label='MobileNetV2',c='orange',linewidth=2)
ax2.plot(epochs_range,val_loss2, label='VGG19',c='black',linewidth=2)
ax2.plot(epochs_range,val_loss3, label='InceptionResNetV2',c='yellow',linewidth=2)
ax2.legend()

ax2.set_title('Training and Validation')

fig.tight_layout(pad=3.0)
plt.show()